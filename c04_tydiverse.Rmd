# Manipulación de datos con tidyverse

<p style="text-align: justify;">

La mayoría de los paquetes que aprenderá en este apartado son parte del llamado **tidyverse**. Los paquetes de tidyverse comparten una filosofía común de programación de datos y R, y están diseñados para trabajar juntos de forma natural.

</p>

Puedes instalar tidyverse completo con una sola línea de código:

```{r message=FALSE, warning=FALSE, eval=FALSE}
install.packages("tidyverse")
```

<p style="text-align: justify;">

En su propia computadora, escriba esa línea de código en la consola y luego presione Entrar para ejecutarlo. R descargará los paquetes de CRAN y los instalará en su computadora. Si tiene problemas con la instalación, asegúrese de estar conectado a Internet y de que **https://cloud.r-project.org/** no esté bloqueado por su firewall o proxy.

</p>

```{r tidyverse, message=TRUE, warning=FALSE}
library(tidyverse)
```

<p style="text-align: justify;">

Esto le indica que tidyverse está cargando los paquetes **ggplot2, tibble, tidyr, readr, purrr y dplyr**. Estos consideran los núcleo del tidyverse porque los usará en casi todos los análisis.

</p>

<p style="text-align: justify;">

Los paquetes del tidyverse cambian con bastante frecuencia. Puede ver si hay actualizaciones disponibles y, opcionalmente, instalarlas, ejecutando **`tidyverse_update()`**.

</p>

<p style="text-align: justify;">

Toma nota del mensaje de conflictos que se imprime cuando cargas el tidyverse. Te dice que dplyr sobrescribe algunas funciones en base R. Si desea usar la versión base de estas funciones después de cargar dplyr, deberá usar sus nombres completos: **`stats::filter()`** y **`stats::lag()`**

</p>

## Data Transformation con dplyr

<p style="text-align: justify;">

La visualización es una herramienta importante para la generación de información, pero es raro que obtenga los datos exactamente en la forma correcta que necesita. A menudo, necesitará crear algunas variables o resúmenes nuevos, o tal vez solo desee cambiar el nombre de las variables o reordenar las observaciones para que sea un poco más fácil trabajar con los datos. Aprenderá a hacer todo eso **(¡y más!)** en este apartado, que le enseñará cómo transformar sus datos utilizando el [**paquete dplyr**](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)

Para explorar los verbos básicos de manipulación de datos de **dplyr**, usaremos la base de datos de zonas de amortiguamiento. Este marco de datos contiene. Los datos provienen de la [Servicio Nacional de Áreas Naturales Protegidas (SERNANP)]{style="color:blue"}

</p>

```{r}
# Los datos serán un 'data frame'
z_amortiguamiento<- read.csv(file = 'data/zona_amortiguamiento.csv', fileEncoding="latin1",sep = ";")
head(z_amortiguamiento)
```

### Dplyr Básico

En este capítulo, aprenderá las cinco funciones clave de **dplyr** que le permiten resolver la gran mayoría de desafíos en la manipulación de datos:

-   Elija observaciones por sus valores (**`filter()`**).
-   Reordenar las filas (**`arrange()`**).
-   Elija las variables por sus nombres (**`select()`**).
-   Crear nuevas variables con funciones de variables existentes (**`mutate()`**).
-   Colapsar muchos valores en un solo resumen (**`summarize()`**)

<p style="text-align: justify;">

Todos estos se pueden usar junto con **`group_by()`**, que cambia el alcance de cada función de operar en todo el conjunto de datos a operar grupo por grupo. Estas seis funciones proporcionan los **verbos** para un lenguaje de manipulación de datos.

</p>

Todos los verbos funcionan de manera similar:

1.  El primer argumento es un marco de datos.
2.  Los argumentos siguientes describen qué hacer con el marco de datos, utilizando los nombres de las variables **(sin comillas)**.
3.  El resultado es un nuevo dataframe.

<p style="text-align: justify;">

Juntando, estas propiedades hacen que sea fácil encadenar varios pasos simples para lograr un resultado complejo. Profundicemos y veamos como funcionan estos verbos.

</p>

### Filtrar filas con filter()

<p align="center">

<img src="fig/filter.png" width="500"/>

</p>

**Filter()**te permite filtrar un subconjunto de observaciones según sus valores. El primer argumento es el nombre del data frame. El segundo y los siguientes argumentos son las expresiones que lo filtran.

Por ejemplo, podemos seleccionar todas las **Superficie igual a 310242.10** con:

```{r}
dplyr::filter(z_amortiguamiento, Superficie == 310242.10 ) 
```

Cuando ejecutas esa línea de código, dplyr ejecuta la operación de filtrado y devuelve un nuevo data frame. Las funciones de dplyr nunca modifican su input, por lo que si deseas guardar el resultado, necesitarás usar el operador de asignación, \<-:

```{r}
filter01 <- dplyr::filter(z_amortiguamiento,Superficie == 310242.10 )
```

De otro modo usar el operador **"%\>%"** de la librería **magrittr**.

R imprime los resultados o los guarda en una variable. Si desea hacer ambas cosas, puede envolver la tarea **entre paréntesis**:

```{r df-drop-ok, class.source="bg-success"}
(filter02 <- dplyr::filter(z_amortiguamiento,Superficie == 310242.10))
```

#### Comparaciones

Para usar el filtrado de manera efectiva, debes saber cómo seleccionar las observaciones que deseas utilizando los operadores de comparación. R proporciona el conjunto estándar: `>`, `>=`, `<`, `<=`, `!=` (no igual) y `==` (igual).

Cuando comienzas con R, el error más fácil de cometer es usar `=` en lugar de `==` cuando se busca igualdad. Cuando esto suceda, obtendrás un error informativo:

```{r echo=TRUE, message=TRUE, warning=TRUE, error=TRUE}
dplyr::filter(z_amortiguamiento,Superficie = 310242.10)
```

Hay otro problema común que puedes encontrar al usar `==`: los números de coma flotante. **¡Estos resultados pueden sorprenderte!**

```{r}
sqrt(2)^2 == 2
1 / 49 * 49 == 1
```

Las computadoras usan **aritmética de precisión finita** (obviamente, **NO** pueden **almacenar** una **cantidad infinita de dígitos**), así que recuerda que cada número que observas es una aproximación. En lugar de confiar en **`==`**, usa **`near()`** (cercano, en inglés):

```{r}
near(sqrt(2)^2, 2)
near(1 / 49 * 49, 1)
```

#### Operadores lógicos

Si tienes múltiples argumentos para **`filter()`** estos se combinan con **"y"**: cada expresión debe ser verdadera para que una fila se incluya en el output. Para otros tipos de combinaciones necesitarás usar operadores Booleanos: **& es "y"**, **\| es "o"**, y **! es "no"**. La siguiente figura muestra el conjunto completo de operaciones **Booleanas**.

<p align="center">

<img src="https://es.r4ds.hadley.nz/diagrams_w_text_as_path/es/transform-logical.svg" width="500"/>

</p>

El siguiente código sirve para encontrar todas las areas iguales a `310242.10` o `1880.50`:

```{r}
dplyr::filter(z_amortiguamiento,Superficie == 310242.10 | Superficie == 1880.50)
```

El orden de las operaciones no funciona como en español. No puedes escribir **`filter(z_amortiguamiento, Superficie == (310242.10 | 1880.50))`**, que literalmente puede traducirse como **"encuentra todas las areas de 310242.10 o 1880.50"**. En cambio, encontrará todos los areas que son iguales a **310242.10 \| 1880.50**, una expresión que resulta en **'TRUE'** (verdadero). En un contexto numérico (como aquí), **'TRUE' se convierte en uno**, por lo que **encuentra** todos las **areas de 310242.10**, **NO** en **310242.10 o 1880.50**. ¡Esto es bastante confuso!

Una manera rápida y útil para resolver este problema es **`x %in% y`** (es decir, x en y). Esto **seleccionará cada fila donde x es uno de los valores en y**. Podríamos usarlo para reescribir el código de arriba:

```{r}
dplyr::filter(z_amortiguamiento, Superficie %in% c(310242.10, 1880.50))
```

A veces puedes simplificar subconjuntos complicados al recordar **la ley de De Morgan**: **!(x & y)** es lo mismo que **!x \| !y**, y **!(x \| y)** es lo mismo que \*\*!x & !y\*. Por ejemplo, si deseas encontrar areas mayores a `26.2` y menores `8652.24` .

```{r}
dplyr::filter(z_amortiguamiento,!(Superficie > 8652.24  | Superficie < 26.2)) %>% head()
```

### Reordenar las filas con arrange()

**`arrange()** funciona de manera similar a`filter()\` excepto que en lugar de seleccionar filas, cambia su orden. La función toma un** dataframe\*\* y un conjunto de nombres de columnas (o expresiones más complicadas) para ordenar según ellas. Si proporcionas más de un nombre de columna, cada columna adicional se utilizará para romper empates en los valores de las columnas anteriores:

```{r}
arrange(z_amortiguamiento, Codigo) %>% head()
```

Usa **`desc()`** para reordenar por una columna en orden descendente:

```{r}
arrange(z_amortiguamiento, desc(Superficie)) %>% head()
```

### Seleccionar columnas con select()

<p align="center">

<img src="fig/select.png" width="500"/>

</p>

No es raro obtener conjuntos de datos con cientos o incluso miles de variables. En este caso, el primer desafío a menudo se reduce a las variables que realmente te interesan. `select()` te permite seleccionar rápidamente un subconjunto útil utilizando operaciones basadas en los nombres de las variables.

`select()` no es muy útil con los datos de los vuelos porque solo tenemos 19 variables, pero de todos modos se entiende la idea general:

```{r}
# Seleccionar columnas por nombre
dplyr::select(z_amortiguamiento, Codigo, Area_natural) %>% head()
# Seleccionar todas las columnas entre anio y dia (incluyente)
dplyr::select(z_amortiguamiento, Codigo:Periodo) %>% head()
# Seleccionar todas las columnas excepto aquellas entre anio en dia (incluyente)
dplyr::select(z_amortiguamiento, -(Codigo:Periodo)) %>% head()
```

Hay una serie de **funciones auxiliares** que puedes usar dentro de `select()`:

-   **`starts_with("abc")`**: coincide con los nombres que comienzan con "abc".
-   **`ends_with("xyz")`**: coincide con los nombres que terminan con "xyz".
-   **`contains("ijk")`**: coincide con los nombres que contienen "ijk".
-   **`matches("(.)\\1")`**: selecciona variables que coinciden con una expresión regular **(regex)**. Esta en particular coincide con cualquier variable que contenga caracteres repetidos.
-   **`num_range("x", 1:3)`**: coincide con x1,x2 y x3.

Consulta `?select` para ver más detalles.

`select()` se puede usar para cambiar el nombre de las variables, pero rara vez es útil porque descarta todas las variables que no se mencionan explícitamente. En su lugar, utiliza **`rename()`**, que es una variante de `select()` que mantiene todas las variables que no se mencionan explícitamente:

```{r}
names(z_amortiguamiento)
# new name = old name
df <- rename(z_amortiguamiento, "Baselegal" = Base_legal) 
names(df)
```

Otra opción es usar `select()` junto con el auxiliar **`everything()`** (todo, en inglés). Esto es útil si tienes un grupo de variables que te gustaría mover al comienzo del data frame.

```{r fig.width=20}
dplyr::select(z_amortiguamiento, Superficie, everything()) %>% head()
```

### Añadir nuevas variables con mutate()

<p align="center">

<img src="fig/mutate.png" width="500"/>

</p>

Además de seleccionar conjuntos de columnas existentes, a menudo es útil crear nuevas columnas en función de columnas existentes. Ese es el trabajo de **`mutate()`** (del inglés mutar o transformar).

**`mutate()`** siempre agrega nuevas columnas al final de un conjunto de datos, así que comenzaremos creando un conjunto de datos más pequeño para que podamos ver las nuevas variables. Recuerda que cuando usas **RStudio**, la manera más fácil de ver todas las columnas es **View()**.

```{r}

# Área natural 
area_natural<-read.csv2(file = 'data/anp_definitivo.csv')
```

Ten en cuenta que puedes hacer referencia a las columnas que acabas de crear:

```{r}

# Área natural 
superficie_anp<-dplyr::select(area_natural,c(anp_cate:anp_nomb,anp_ubpo:anp_suleg))

mutate(superficie_anp, area_km2 = as.numeric(anp_suleg)/100)
```

Si `solo quieres conservar las nuevas variables`, usa **`transmute()`**:

```{r}
transmute(superficie_anp,area_km2 = as.numeric(anp_suleg)/100)

```

### Resúmenes agrupados con summarise()

El último verbo clave es **`summarise()`** (resumir, en inglés). Se encarga de colapsar un data frame en una sola fila:

```{r}
summarize(superficie_anp, superficie_media = mean(as.numeric(anp_suleg), na.rm = TRUE))
```

`summarise()` no es muy útil a menos que lo enlacemos con `group_by()`. Esto cambia la unidad de análisis del conjunto de datos completo a grupos individuales. Luego, cuando uses los verbos **dplyr** en un data frame agrupado, estos se aplicarán automáticamente **"por grupo"**. Por ejemplo, si aplicamos exactamente el mismo código a un dataframe agrupado por fecha, obtenemos el retraso promedio por fecha:

```{r}
by_anp <- group_by(area_natural,anp_cate)
summarize(by_anp, superficie_media = mean(as.numeric(anp_suleg), na.rm = TRUE))
```

Juntos `group_by()` y `summarise()` proporcionan una de las herramientas que más comúnmente usarás cuando trabajes con dplyr: resúmenes agrupados. Pero antes de ir más allá con esto, tenemos que introducir una idea nueva y poderosa: el `pipe` (pronunciado /paip/, que en inglés significa ducto o tubería).

## Combinación de múltiples operaciones con el pipe

Imagina que queremos explorar la relación entre la distancia y el atraso promedio para cada ubicación. Usando lo que sabes acerca de dplyr, podrías escribir un código como este:

```{r warning=FALSE}
by_anp <- group_by(area_natural,anp_cate)
delay <-
  summarize(
    by_anp,
    count = n(),
    dist = mean(anp_suleg, na.rm = TRUE),
)
# Parece que las demoras aumentan con las distancias hasta ~ 750 millas
# y luego disminuyen. ¿Tal vez a medida que los vuelos se hacen más 
# largos, hay más habilidad para compensar las demoras en el aire?
ggplot(data = delay, mapping = aes(x = dist, y = delay)) +
 geom_point(aes(size = count), alpha = 1/3) +
 geom_smooth(se = FALSE)
```

Hay tres pasos para preparar esta información:

1.  Agrupar los vuelos por destino.
2.  Resumir para calcular la distancia, la demora promedio y el número de vuelos en cada grupo.
3.  Filtrar para eliminar puntos ruidosos y el aeropuerto de Honolulu, que está casi dos veces más lejos que el próximo aeropuerto más cercano.

Es un poco frustrante escribir este código porque tenemos que dar un nombre a cada data frame intermedio, incluso si el dataframe en sí mismo no nos importa. Nombrar cosas es difícil y **dilata el tiempo** de nuestro análisis.

Hay otra forma de abordar el mismo problema con el pipe, **`%>%`**:

```{r}
delays <- flights %>% 
  group_by(dest) %>% 
  summarise(
    count = n(),
    dist = mean(distance, na.rm = TRUE),
    delay = mean(arr_delay, na.rm = TRUE)
  ) %>% 
  filter(count > 20, dest != "HNL")
```

Este código se enfoca en las transformaciones, no en lo que se está transformando, lo que hace que sea más fácil de leer. Puedes leerlo como una serie de declaraciones imperativas: **agrupa**, luego **resume** y luego **filtra**. Como sugiere esta lectura, una buena forma de pronunciar **`%>%`** cuando se lee el código es **"luego"**.

Lo que ocurre detrás del código, es que **x %\>% f(y)** se convierte en **f(x, y)**, y **x %\>% f(y) %\>% g(z)** se convierte en **g(f(x, y), z)** y así sucesivamente. Puedes usar el ***pipe*** para reescribir múltiples operaciones de forma que puedas leer de izquierda a derecha, de arriba hacia abajo. **Usaremos pipes con frecuencia a partir de ahora porque mejora considerablemente la legibilidad del código**. Volveremos a este tema con más detalles en pipes.

Trabajar con el pipe es uno de los criterios clave para pertenecer al tidyverse. La única excepción es ggplot2: se escribió antes de que se descubriera el pipe. Lamentablemente, la siguiente iteración de ggplot2, ggvis, que sí utiliza el pipe, aún no está lista para el horario estelar.

### Valores faltantes

Es posible que te hayas preguntado sobre el argumento na.rm que utilizamos anteriormente. ¿Qué pasa si no lo configuramos?

```{r}
flights %>% 
  group_by(year, month, day) %>% 
  summarise(mean = mean(dep_delay))
```

¡Obtenemos muchos valores faltantes! Esto se debe a que las funciones de agregación obedecen la regla habitual de valores faltantes: **si hay uno en el input**, **el output también será un valor faltante**. Afortunadamente, todas las funciones de agregación tienen un argumento **`na.rm`** que elimina los valores faltantes antes del cálculo:

```{r}
flights %>% 
  group_by(year, month, day) %>% 
  summarise(mean = mean(dep_delay, na.rm = TRUE))
```

En este caso, en el que los valores faltantes representan vuelos cancelados, también podríamos abordar el problema eliminando primero este tipo de vuelos. Guardaremos este conjunto de datos para poder reutilizarlo en los siguientes ejemplos.

```{r}
not_cancelled <- flights %>% 
  filter(!is.na(dep_delay), !is.na(arr_delay))

not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(mean = mean(dep_delay))
```

#### Conteos

Siempre que realices una agregación, es una buena idea incluir un conteo (**n()**) o un recuento de valores no faltantes (**sum(!is.na(x))**). De esta forma, puedes verificar que no estás sacando conclusiones basadas en cantidades muy pequeñas de datos. Por ejemplo, veamos los aviones (identificados por su número de cola) que tienen las demoras promedio más altas:

```{r}
delays <- not_cancelled %>% 
  group_by(tailnum) %>% 
  summarise(
    delay = mean(arr_delay)
  )

ggplot(data = delays, mapping = aes(x = delay)) + 
  geom_freqpoly(binwidth = 10) +
  theme_bw()
```

[¡Hay algunos aviones que tienen una demora promedio de 5 horas (300 minutos)!]{style="color:blue"}

</p>

La historia es en realidad un poco más matizada. Podemos obtener más información si hacemos un diagrama de dispersión del número de vuelos contra la demora promedio:

```{r}
delays <- not_cancelled %>% 
  group_by(tailnum) %>% 
  summarise(
    delay = mean(arr_delay, na.rm = TRUE),
    n = n()
  )

ggplot(data = delays, mapping = aes(x = n, y = delay)) + 
  geom_point(alpha = 1/10) +
  theme_bw()
```

No es sorprendente que haya una mayor variación en el promedio de retraso cuando hay pocos vuelos. La forma de este gráfico es muy característica: cuando trazas un promedio (o cualquier otra medida de resumen) contra el tamaño del grupo, verás que la variación decrece a medida que el tamaño de muestra aumenta.

Cuando se observa este tipo de gráficos, resulta útil eliminar los grupos con menor número de observaciones, ya que puedes ver más del patrón y menos de la variación extrema de los grupos pequeños. Esto es lo que hace el siguiente bloque de código. También te ofrece una manera muy útil para integrar ggplot2 en el flujo de trabajo de dplyr. **Es un poco incómodo tener que cambiar de %\>% a +**, pero una vez que entiendas el código, verás que es bastante conveniente.

```{r}
delays %>% 
  filter(n > 25) %>% 
  ggplot(mapping = aes(x = n, y = delay)) + 
    geom_point(alpha = 1/10) +
    theme_bw()
```

------------------------------------------------------------------------

Hay otra variación común de este tipo de patrón. Veamos cómo el rendimiento promedio de los bateadores en el béisbol está relacionado con el número de veces que les toca batear. Aquí utilizaremos el conjunto de datos de bateadores para calcular el promedio de bateo (número de bateos / número de intentos) de cada jugador de béisbol de las Grandes Ligas.

Cuando graficamos la habilidad del bateador (medido por el promedio de bateo, pb) contra el número de oportunidades para golpear la pelota (medido por el tiempo al bate,ab), verás dos patrones:

1.  Como en el ejemplo anterior, la variación en nuestro estadístico de resumen disminuye a medida que obtenemos más observaciones.

2.  Existe una correlación positiva entre la habilidad (pb) y las oportunidades para golpear la pelota (ab). Esto se debe a que los equipos controlan quién puede jugar y, obviamente, elegirán a sus mejores jugadores.

```{r}
# Convert to a tibble so it prints nicely
bateo <- as_tibble(datos::bateadores)

rendimiento_bateadores <- bateo %>% 
  group_by(id_jugador) %>% 
  summarise(
    pb = sum(golpes, na.rm = TRUE) / sum(al_bate, na.rm = TRUE),
    ab = sum(al_bate, na.rm = TRUE)
  )

rendimiento_bateadores %>% 
  filter(ab > 100) %>% 
  ggplot(mapping = aes(x = ab, y = pb)) +
  geom_point() +
  geom_smooth(se = FALSE) +
  theme_bw()
```

Esto también tiene implicaciones importantes para la clasificación. Si ingenuamente ordenas **`desc(pb)`**, verás que las personas con los mejores promedios de bateo tienen claramente mucha suerte, pero no son necesariamente hábiles:

Puedes encontrar una buena explicación de este problema en <http://varianceexplained.org/r/empirical_bayes_baseball/> y <http://www.evanmiller.org/how-not-to-sort-by-average-rating.html>.

## Funciones de resumen útiles

Solo el uso de medias, conteos y sumas puede llevarte muy lejos, pero R proporciona muchas otras funciones de resumen útiles:

-   **Medidas de posición:** `first(x)`, `nth(x, 2)`, `last(x)`. Estas trabajan de forma similar a `x[1]`, `x[2]` y `x[length (x)]`, pero te permiten establecer un valor predeterminado en el caso de que esa posición no exista (es decir, si estás tratando de obtener el tercer elemento de un grupo que solo tiene dos elementos). Por ejemplo, podemos encontrar la primera (first) y última (last) salida para cada día:

```{r message=FALSE}
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    first_dep = first(dep_time), 
    last_dep = last(dep_time)
  )
```

-   **Medidas de centralidad:** hemos usado `mean(x)`, pero `median(x)` también resulta muy útil. La media es la suma dividida por el número de observaciones; la mediana es un valor donde el 50% de x está por encima de él y el 50% está por debajo. A veces es útil combinar agregación con un subconjunto lógico.

```{r message=FALSE, warning=FALSE}
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    avg_delay1 = mean(arr_delay),
    avg_delay2 = mean(arr_delay[arr_delay > 0]) # the average positive delay
  )
```

-   **Medidas de rango:** `min(x)`, `quantile(x, 0.25)`, `max(x)`. Los cuantiles son una generalización de la mediana. Por ejemplo, `quantile(x, 0.25)` encontrará un valor de x que sea mayor a 25% de los valores, y menor que el 75% restante.

```{r}
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(
    first = min(dep_time),
    last = max(dep_time)
  )
```

-   **Medidas de dispersión:** `sd(x)`, `IQR(x)`, `mad(x)`. La raíz cuadrad de la varianza o desviación estándar `sd(x)` es una medida estándar de dispersión. El rango intercuartil `IQR()` y la desviación media absoluta `mad(x`) son medidas robustas equivalentes que pueden ser más útiles si tienes **valores atípicos**.

```{r}
not_cancelled %>% 
  group_by(dest) %>% 
  summarise(distance_sd = sd(distance)) %>% 
  arrange(desc(distance_sd))
```

Estas funciones son complementarias al filtrado en rangos. El filtrado te proporciona todas las variables, con cada observación en una fila distinta:

```{r}
not_cancelled %>% 
  group_by(year, month, day) %>% 
  mutate(r = min_rank(desc(dep_time))) %>% 
  filter(r %in% range(r)) %>%
  dplyr::select(r)
```

-   **Conteos:** has visto `n()`, que no toma argumentos y que devuelve el tamaño del grupo actual. Para contar la cantidad de valores no faltantes, usa `sum(!is.na (x))`. Para contar la cantidad de valores distintos (únicos), usa `n_distinct(x)`.

```{r}
# ¿Qué destinos tienen la mayoría de las aerolíneas?
not_cancelled %>% 
  group_by(dest) %>% 
  summarise(carriers = n_distinct(carrier)) %>% 
  arrange(desc(carriers))
```

Los conteos son tan útiles que **dplyr** proporciona un ayudante simple si todo lo que quieres es un conteo:

```{r}
not_cancelled %>% 
  count(dest)
```

Opcionalmente puedes proporcionar una variable de ponderación. Por ejemplo, podrías usar esto para **"contar"** (sumar) el número total de millas que voló un avión:

```{r}
not_cancelled %>% 
  count(tailnum, wt = distance)
```

-   **Conteos y proporciones de valores lógicos:** `sum(x > 10)`, `mean(y == 0)`. Cuando se usan con funciones numéricas, `TRUE` se convierte en **1** y `FALSE` en **0**. Esto hace que `sum()` y `mean()` sean muy útiles: `sum(x)` te da la cantidad de `TRUE` en `x`, y `mean(x)` te da la proporción.

```{r}
# ¿Cuántos vuelos salieron antes de las 5 am? 
# (estos generalmente son vuelos demorados del día anterior)
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(n_early = sum(dep_time < 500))
# ¿Qué proporción de vuelos se retrasan más de una hora?
not_cancelled %>% 
  group_by(year, month, day) %>% 
  summarise(hour_prop = mean(arr_delay > 60))
```

### Agrupación por múltiples variables

Cuando agrupas por múltiples variables, cada resumen se desprende de un nivel de la agrupación. Eso hace que sea más fácil acumular progresivamente en un conjunto de datos:

```{r}
daily <- group_by(flights, year, month, day)
(per_day   <- summarise(daily, flights = n()))
(per_month <- summarise(per_day, flights = sum(flights)))
(per_year  <- summarise(per_month, flights = sum(flights)))
```

Ten cuidado al acumular resúmenes progresivamente: está bien para las sumas y los recuentos, pero debes pensar en la ponderación de las medias y las varianzas, además de que no es posible hacerlo exactamente para estadísticas basadas en rangos como la mediana. En otras palabras, la suma de las sumas agrupadas es la suma total, pero la mediana de las medianas agrupadas no es la mediana general.

### Desagrupar

Si necesitas eliminar la agrupación y regresar a las operaciones en datos desagrupados, usa ungroup().

```{r}
daily %>% 
  ungroup() %>%             # no longer grouped by date
  summarise(flights = n())  # all flights
```

<span style="color:blue">**Ejercicios**

<span style="color:blue">1. Haz una lluvia de ideas de al menos 5 formas diferentes de evaluar las características de un retraso típico de un grupo de vuelos. Considera los siguientes escenarios:

<span style="color:blue">- Un vuelo llega 15 minutos antes 50% del tiempo, y 15 minutos tarde 50% del tiempo.

<span style="color:blue">- Un vuelo llega siempre 10 minutos tarde.

<span style="color:blue">- Un vuelo llega 30 minutos antes 50% del tiempo, y 30 minutos tarde 50% del tiempo.

<span style="color:blue">- Un vuelo llega a tiempo en el 99% de los casos. 1% de las veces llega 2 horas tarde.

<span style="color:blue">¿Qué es más importante: retraso de la llegada o demora de salida?

<span style="color:blue">2. Sugiere un nuevo enfoque que te dé el mismo output que no_cancelados %\>% count(destino) y no_cancelado %\>% count(codigo_cola, wt = distancia) (sin usar count()).

<span style="color:blue">3. Nuestra definición de vuelos cancelados (is.na(atraso_salida) \| is.na (atraso_llegada)) es un poco subóptima. ¿Por qué? ¿Cuál es la columna más importante?

<span style="color:blue">4. Mira la cantidad de vuelos cancelados por día. ¿Hay un patrón? ¿La proporción de vuelos cancelados está relacionada con el retraso promedio?

<span style="color:blue">5. ¿Qué compañía tiene los peores retrasos? Desafío: ¿puedes desenredar el efecto de malos aeropuertos vs. el efecto de malas aerolíneas? ¿Por qué o por qué no? (Sugerencia: piensa en vuelos %\>% group_by(aerolinea, destino) %\>% summarise(n()))

[6. ¿Qué hace el argumento sort a count(). ¿Cuándo podrías usarlo?]{style="color:blue"}

### Transformaciones agrupadas (y filtros)

La agrupación es más útil si se utiliza junto con summarise(), pero también puedes hacer operaciones convenientes con `mutate()` y `filter()`:

-   Encuentra los peores miembros de cada grupo:

```{r}
flights_sml %>% 
  group_by(year, month, day) %>%
  filter(rank(desc(arr_delay)) < 10)
```

Encuentra todos los grupos más grandes que un determinado umbral:

```{r}
popular_dests <- flights %>% 
  group_by(dest) %>% 
  filter(n() > 365)
popular_dests
```

-   Estandariza para calcular las métricas por grupo:

```{r}
popular_dests %>% 
  filter(arr_delay > 0) %>% 
  mutate(prop_delay = arr_delay / sum(arr_delay)) %>% 
  select(year:day, dest, arr_delay, prop_delay)
```

Un filtro agrupado es una transformación agrupada seguida de un filtro desagrupado. En general, preferimos evitarlos, excepto para las manipulaciones rápidas y sucias: de lo contrario, es difícil comprobar que has hecho la manipulación correctamente.

Las funciones que trabajan de forma más natural en transformaciones agrupadas y filtros se conocen como funciones de ventana o window functions (frente a las funciones de resumen utilizadas para los resúmenes). Puedes obtener más información sobre las funciones de ventana útiles en la viñeta correspondiente: `vignette("window-functions")`.
